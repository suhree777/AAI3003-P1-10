{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bryon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bryon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords    # For stopwords\n",
    "\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('stopwords')   # Downloading stopwords data\n",
    "nltk.download('punkt')       # Downloading tokenizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   message_id                                               text  label  \\\n",
      "0       33214  any software just for 15 $ - 99 $ understandin...      1   \n",
      "1       11929  perspective on ferc regulatory action client c...      0   \n",
      "2       19784  wanted to try ci 4 lis but thought it was way ...      1   \n",
      "3        2209  enron / hpl actuals for december 11 , 2000 tec...      0   \n",
      "4       15880  looking for cheap high - quality software ? ro...      1   \n",
      "\n",
      "  label_text                                            subject  \\\n",
      "0       spam                  any software just for 15 $ - 99 $   \n",
      "1        ham  perspective on ferc regulatory action client c...   \n",
      "2       spam  wanted to try ci 4 lis but thought it was way ...   \n",
      "3        ham         enron / hpl actuals for december 11 , 2000   \n",
      "4       spam  looking for cheap high - quality software ? ro...   \n",
      "\n",
      "                                             message       date  \n",
      "0  understanding oem software\\nlead me not into t... 2005-06-18  \n",
      "1  19 th , 2 : 00 pm edt\\nperspective on ferc reg... 2001-06-19  \n",
      "2  viagra at $ 1 . 12 per dose\\nready to boost yo... 2004-09-11  \n",
      "3  teco tap 30 . 000 / enron ; 120 . 000 / hpl ga... 2000-12-12  \n",
      "4  water past also , burn , course . gave country... 2005-02-13  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the Hugging Face library\n",
    "dataset = load_dataset('SetFit/enron_spam')\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3ec9 th {\n",
       "  color: black;\n",
       "  background-color: #FC0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3ec9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3ec9_level0_col0\" class=\"col_heading level0 col0\" >message_id</th>\n",
       "      <th id=\"T_c3ec9_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "      <th id=\"T_c3ec9_level0_col2\" class=\"col_heading level0 col2\" >label</th>\n",
       "      <th id=\"T_c3ec9_level0_col3\" class=\"col_heading level0 col3\" >label_text</th>\n",
       "      <th id=\"T_c3ec9_level0_col4\" class=\"col_heading level0 col4\" >subject</th>\n",
       "      <th id=\"T_c3ec9_level0_col5\" class=\"col_heading level0 col5\" >message</th>\n",
       "      <th id=\"T_c3ec9_level0_col6\" class=\"col_heading level0 col6\" >date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3ec9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c3ec9_row0_col0\" class=\"data row0 col0\" >33214</td>\n",
       "      <td id=\"T_c3ec9_row0_col1\" class=\"data row0 col1\" >any software just for 15 $ - 99 $ understanding oem software\n",
       "lead me not into temptation ; i can find the way myself .\n",
       "# 3533 . the law disregards trifles .</td>\n",
       "      <td id=\"T_c3ec9_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_c3ec9_row0_col3\" class=\"data row0 col3\" >spam</td>\n",
       "      <td id=\"T_c3ec9_row0_col4\" class=\"data row0 col4\" >any software just for 15 $ - 99 $</td>\n",
       "      <td id=\"T_c3ec9_row0_col5\" class=\"data row0 col5\" >understanding oem software\n",
       "lead me not into temptation ; i can find the way myself .\n",
       "# 3533 . the law disregards trifles .</td>\n",
       "      <td id=\"T_c3ec9_row0_col6\" class=\"data row0 col6\" >2005-06-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3ec9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c3ec9_row1_col0\" class=\"data row1 col0\" >11929</td>\n",
       "      <td id=\"T_c3ec9_row1_col1\" class=\"data row1 col1\" >perspective on ferc regulatory action client conf call today , jun e 19 th , 2 : 00 pm edt\n",
       "perspective on ferc regulatory action client conference call\n",
       "today , tuesday , june 19 th\n",
       "2 : 00 pm edt\n",
       "host : ray niles , power / natural gas analyst\n",
       "speaker : steve bergstrom , president & coo of dynegy\n",
       "steve bergstrom , president and chief operating officer of dynegy , will join\n",
       "us at 2 : 00 p . m . today for a conference call discussion of the recent ferc\n",
       "action imposing price controls in the west . the discussion will be followed\n",
       "by q & a .\n",
       "questions to be explored include :\n",
       "what are the implications of the ferc action , for dyn and the industry as a\n",
       "whole ?\n",
       "what is the earnings impact ?\n",
       "what are the risks of further re - regulation ?\n",
       "and whatever else is on your minds\n",
       "we attach two recent notes on the ferc action for your reference .\n",
       "call in replay reservation\n",
       "800 - 229 - 0281 us 800 - 642 - 1687 us 1073259\n",
       "706 - 645 - 9237 int ' l 706 - 645 - 9291 int ' l\n",
       "replay until 6 / 22 , 11 : 59 pm\n",
       "raymond c . niles\n",
       "power / natural gas research\n",
       "salomon smith barney\n",
       "( 212 ) 816 - 2807\n",
       "ray . niles @ ssmb . com\n",
       "s</td>\n",
       "      <td id=\"T_c3ec9_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_c3ec9_row1_col3\" class=\"data row1 col3\" >ham</td>\n",
       "      <td id=\"T_c3ec9_row1_col4\" class=\"data row1 col4\" >perspective on ferc regulatory action client conf call today , jun e</td>\n",
       "      <td id=\"T_c3ec9_row1_col5\" class=\"data row1 col5\" >19 th , 2 : 00 pm edt\n",
       "perspective on ferc regulatory action client conference call\n",
       "today , tuesday , june 19 th\n",
       "2 : 00 pm edt\n",
       "host : ray niles , power / natural gas analyst\n",
       "speaker : steve bergstrom , president & coo of dynegy\n",
       "steve bergstrom , president and chief operating officer of dynegy , will join\n",
       "us at 2 : 00 p . m . today for a conference call discussion of the recent ferc\n",
       "action imposing price controls in the west . the discussion will be followed\n",
       "by q & a .\n",
       "questions to be explored include :\n",
       "what are the implications of the ferc action , for dyn and the industry as a\n",
       "whole ?\n",
       "what is the earnings impact ?\n",
       "what are the risks of further re - regulation ?\n",
       "and whatever else is on your minds\n",
       "we attach two recent notes on the ferc action for your reference .\n",
       "call in replay reservation\n",
       "800 - 229 - 0281 us 800 - 642 - 1687 us 1073259\n",
       "706 - 645 - 9237 int ' l 706 - 645 - 9291 int ' l\n",
       "replay until 6 / 22 , 11 : 59 pm\n",
       "raymond c . niles\n",
       "power / natural gas research\n",
       "salomon smith barney\n",
       "( 212 ) 816 - 2807\n",
       "ray . niles @ ssmb . com\n",
       "s</td>\n",
       "      <td id=\"T_c3ec9_row1_col6\" class=\"data row1 col6\" >2001-06-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3ec9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c3ec9_row2_col0\" class=\"data row2 col0\" >19784</td>\n",
       "      <td id=\"T_c3ec9_row2_col1\" class=\"data row2 col1\" >wanted to try ci 4 lis but thought it was way too expensive for you ? viagra at $ 1 . 12 per dose\n",
       "ready to boost your sex life ? positive ?\n",
       "time to do it right now . order viagra at incredibly low prices\n",
       "$ 1 . 12 per dose . unbelivable\n",
       "remove</td>\n",
       "      <td id=\"T_c3ec9_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_c3ec9_row2_col3\" class=\"data row2 col3\" >spam</td>\n",
       "      <td id=\"T_c3ec9_row2_col4\" class=\"data row2 col4\" >wanted to try ci 4 lis but thought it was way too expensive for you ?</td>\n",
       "      <td id=\"T_c3ec9_row2_col5\" class=\"data row2 col5\" >viagra at $ 1 . 12 per dose\n",
       "ready to boost your sex life ? positive ?\n",
       "time to do it right now . order viagra at incredibly low prices\n",
       "$ 1 . 12 per dose . unbelivable\n",
       "remove\n",
       "</td>\n",
       "      <td id=\"T_c3ec9_row2_col6\" class=\"data row2 col6\" >2004-09-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3ec9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c3ec9_row3_col0\" class=\"data row3 col0\" >2209</td>\n",
       "      <td id=\"T_c3ec9_row3_col1\" class=\"data row3 col1\" >enron / hpl actuals for december 11 , 2000 teco tap 30 . 000 / enron ; 120 . 000 / hpl gas daily\n",
       "ls hpl lsk ic 30 . 000 / enron</td>\n",
       "      <td id=\"T_c3ec9_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_c3ec9_row3_col3\" class=\"data row3 col3\" >ham</td>\n",
       "      <td id=\"T_c3ec9_row3_col4\" class=\"data row3 col4\" >enron / hpl actuals for december 11 , 2000</td>\n",
       "      <td id=\"T_c3ec9_row3_col5\" class=\"data row3 col5\" >teco tap 30 . 000 / enron ; 120 . 000 / hpl gas daily\n",
       "ls hpl lsk ic 30 . 000 / enron</td>\n",
       "      <td id=\"T_c3ec9_row3_col6\" class=\"data row3 col6\" >2000-12-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3ec9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c3ec9_row4_col0\" class=\"data row4 col0\" >15880</td>\n",
       "      <td id=\"T_c3ec9_row4_col1\" class=\"data row4 col1\" >looking for cheap high - quality software ? rotated napoleonizes water past also , burn , course . gave country , mass lot . act north\n",
       "good . from , learn form most brother vary . when more for . up\n",
       "stick , century put , song be . test , describe , plain , against wood\n",
       "star . began dress ever group . here oh , most world stay .</td>\n",
       "      <td id=\"T_c3ec9_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "      <td id=\"T_c3ec9_row4_col3\" class=\"data row4 col3\" >spam</td>\n",
       "      <td id=\"T_c3ec9_row4_col4\" class=\"data row4 col4\" >looking for cheap high - quality software ? rotated napoleonizes</td>\n",
       "      <td id=\"T_c3ec9_row4_col5\" class=\"data row4 col5\" >water past also , burn , course . gave country , mass lot . act north\n",
       "good . from , learn form most brother vary . when more for . up\n",
       "stick , century put , song be . test , describe , plain , against wood\n",
       "star . began dress ever group . here oh , most world stay .\n",
       "</td>\n",
       "      <td id=\"T_c3ec9_row4_col6\" class=\"data row4 col6\" >2005-02-13 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1600d021090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_df = df.head()\n",
    "styled_df = styled_df.style.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"color\", 'black'), (\"background-color\", \"#FC0\")]}\n",
    "])\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31716 entries, 0 to 31715\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   message_id  31716 non-null  int64         \n",
      " 1   text        31716 non-null  object        \n",
      " 2   label       31716 non-null  int64         \n",
      " 3   label_text  31716 non-null  object        \n",
      " 4   subject     31716 non-null  object        \n",
      " 5   message     31716 non-null  object        \n",
      " 6   date        31716 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['message_id', 'date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6db8 th {\n",
       "  color: Black;\n",
       "  background-color: #FF00CC;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6db8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c6db8_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_c6db8_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "      <th id=\"T_c6db8_level0_col2\" class=\"col_heading level0 col2\" >label_text</th>\n",
       "      <th id=\"T_c6db8_level0_col3\" class=\"col_heading level0 col3\" >subject</th>\n",
       "      <th id=\"T_c6db8_level0_col4\" class=\"col_heading level0 col4\" >message</th>\n",
       "      <th id=\"T_c6db8_level0_col5\" class=\"col_heading level0 col5\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6db8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c6db8_row0_col0\" class=\"data row0 col0\" >any software just for 15 $ - 99 $ understanding oem software\n",
       "lead me not into temptation ; i can find the way myself .\n",
       "# 3533 . the law disregards trifles .</td>\n",
       "      <td id=\"T_c6db8_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_c6db8_row0_col2\" class=\"data row0 col2\" >spam</td>\n",
       "      <td id=\"T_c6db8_row0_col3\" class=\"data row0 col3\" >any software just for 15 $ - 99 $</td>\n",
       "      <td id=\"T_c6db8_row0_col4\" class=\"data row0 col4\" >understanding oem software\n",
       "lead me not into temptation ; i can find the way myself .\n",
       "# 3533 . the law disregards trifles .</td>\n",
       "      <td id=\"T_c6db8_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6db8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c6db8_row1_col0\" class=\"data row1 col0\" >perspective on ferc regulatory action client conf call today , jun e 19 th , 2 : 00 pm edt\n",
       "perspective on ferc regulatory action client conference call\n",
       "today , tuesday , june 19 th\n",
       "2 : 00 pm edt\n",
       "host : ray niles , power / natural gas analyst\n",
       "speaker : steve bergstrom , president & coo of dynegy\n",
       "steve bergstrom , president and chief operating officer of dynegy , will join\n",
       "us at 2 : 00 p . m . today for a conference call discussion of the recent ferc\n",
       "action imposing price controls in the west . the discussion will be followed\n",
       "by q & a .\n",
       "questions to be explored include :\n",
       "what are the implications of the ferc action , for dyn and the industry as a\n",
       "whole ?\n",
       "what is the earnings impact ?\n",
       "what are the risks of further re - regulation ?\n",
       "and whatever else is on your minds\n",
       "we attach two recent notes on the ferc action for your reference .\n",
       "call in replay reservation\n",
       "800 - 229 - 0281 us 800 - 642 - 1687 us 1073259\n",
       "706 - 645 - 9237 int ' l 706 - 645 - 9291 int ' l\n",
       "replay until 6 / 22 , 11 : 59 pm\n",
       "raymond c . niles\n",
       "power / natural gas research\n",
       "salomon smith barney\n",
       "( 212 ) 816 - 2807\n",
       "ray . niles @ ssmb . com\n",
       "s</td>\n",
       "      <td id=\"T_c6db8_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_c6db8_row1_col2\" class=\"data row1 col2\" >ham</td>\n",
       "      <td id=\"T_c6db8_row1_col3\" class=\"data row1 col3\" >perspective on ferc regulatory action client conf call today , jun e</td>\n",
       "      <td id=\"T_c6db8_row1_col4\" class=\"data row1 col4\" >19 th , 2 : 00 pm edt\n",
       "perspective on ferc regulatory action client conference call\n",
       "today , tuesday , june 19 th\n",
       "2 : 00 pm edt\n",
       "host : ray niles , power / natural gas analyst\n",
       "speaker : steve bergstrom , president & coo of dynegy\n",
       "steve bergstrom , president and chief operating officer of dynegy , will join\n",
       "us at 2 : 00 p . m . today for a conference call discussion of the recent ferc\n",
       "action imposing price controls in the west . the discussion will be followed\n",
       "by q & a .\n",
       "questions to be explored include :\n",
       "what are the implications of the ferc action , for dyn and the industry as a\n",
       "whole ?\n",
       "what is the earnings impact ?\n",
       "what are the risks of further re - regulation ?\n",
       "and whatever else is on your minds\n",
       "we attach two recent notes on the ferc action for your reference .\n",
       "call in replay reservation\n",
       "800 - 229 - 0281 us 800 - 642 - 1687 us 1073259\n",
       "706 - 645 - 9237 int ' l 706 - 645 - 9291 int ' l\n",
       "replay until 6 / 22 , 11 : 59 pm\n",
       "raymond c . niles\n",
       "power / natural gas research\n",
       "salomon smith barney\n",
       "( 212 ) 816 - 2807\n",
       "ray . niles @ ssmb . com\n",
       "s</td>\n",
       "      <td id=\"T_c6db8_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6db8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c6db8_row2_col0\" class=\"data row2 col0\" >wanted to try ci 4 lis but thought it was way too expensive for you ? viagra at $ 1 . 12 per dose\n",
       "ready to boost your sex life ? positive ?\n",
       "time to do it right now . order viagra at incredibly low prices\n",
       "$ 1 . 12 per dose . unbelivable\n",
       "remove</td>\n",
       "      <td id=\"T_c6db8_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_c6db8_row2_col2\" class=\"data row2 col2\" >spam</td>\n",
       "      <td id=\"T_c6db8_row2_col3\" class=\"data row2 col3\" >wanted to try ci 4 lis but thought it was way too expensive for you ?</td>\n",
       "      <td id=\"T_c6db8_row2_col4\" class=\"data row2 col4\" >viagra at $ 1 . 12 per dose\n",
       "ready to boost your sex life ? positive ?\n",
       "time to do it right now . order viagra at incredibly low prices\n",
       "$ 1 . 12 per dose . unbelivable\n",
       "remove\n",
       "</td>\n",
       "      <td id=\"T_c6db8_row2_col5\" class=\"data row2 col5\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6db8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c6db8_row3_col0\" class=\"data row3 col0\" >enron / hpl actuals for december 11 , 2000 teco tap 30 . 000 / enron ; 120 . 000 / hpl gas daily\n",
       "ls hpl lsk ic 30 . 000 / enron</td>\n",
       "      <td id=\"T_c6db8_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_c6db8_row3_col2\" class=\"data row3 col2\" >ham</td>\n",
       "      <td id=\"T_c6db8_row3_col3\" class=\"data row3 col3\" >enron / hpl actuals for december 11 , 2000</td>\n",
       "      <td id=\"T_c6db8_row3_col4\" class=\"data row3 col4\" >teco tap 30 . 000 / enron ; 120 . 000 / hpl gas daily\n",
       "ls hpl lsk ic 30 . 000 / enron</td>\n",
       "      <td id=\"T_c6db8_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6db8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c6db8_row4_col0\" class=\"data row4 col0\" >looking for cheap high - quality software ? rotated napoleonizes water past also , burn , course . gave country , mass lot . act north\n",
       "good . from , learn form most brother vary . when more for . up\n",
       "stick , century put , song be . test , describe , plain , against wood\n",
       "star . began dress ever group . here oh , most world stay .</td>\n",
       "      <td id=\"T_c6db8_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_c6db8_row4_col2\" class=\"data row4 col2\" >spam</td>\n",
       "      <td id=\"T_c6db8_row4_col3\" class=\"data row4 col3\" >looking for cheap high - quality software ? rotated napoleonizes</td>\n",
       "      <td id=\"T_c6db8_row4_col4\" class=\"data row4 col4\" >water past also , burn , course . gave country , mass lot . act north\n",
       "good . from , learn form most brother vary . when more for . up\n",
       "stick , century put , song be . test , describe , plain , against wood\n",
       "star . began dress ever group . here oh , most world stay .\n",
       "</td>\n",
       "      <td id=\"T_c6db8_row4_col5\" class=\"data row4 col5\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16049733b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_df = df.head().style\n",
    "\n",
    "\n",
    "# Modify the color and background color of the table headers (th)\n",
    "styled_df.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"color\", 'Black'), (\"background-color\", \"#FF00CC\"), ('font-weight', 'bold')]}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          0\n",
       "label         0\n",
       "label_text    0\n",
       "subject       0\n",
       "message       0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31716, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2874"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28842, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove Duplicate\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 0 : 51.94508009153318\n",
      "percentage of 1 : 48.05491990846682\n"
     ]
    }
   ],
   "source": [
    "values = df['target'].value_counts()\n",
    "total = values.sum()\n",
    "\n",
    "percentage_0 = (values[0] /total) * 100\n",
    "percentage_1 = (values[1]/ total) *100\n",
    "\n",
    "print('percentage of 0 :' ,percentage_0)\n",
    "print('percentage of 1 :' ,percentage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Porter Stemmer for text stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Importing the string module for handling special characters\n",
    "import string\n",
    "\n",
    "# Creating an instance of the Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    # Transform the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization using NLTK\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing special characters\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # Removing stop words and punctuation\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    # Loop through the tokens and remove stopwords and punctuation\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # Stemming using Porter Stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m styled_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mstyle\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[13], line 30\u001b[0m, in \u001b[0;36mtransform_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Loop through the tokens and remove stopwords and punctuation\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation:\n\u001b[0;32m     31\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Stemming using Porter Stemmer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\data.py:324\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 324\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         stream \u001b[38;5;241m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "styled_df = df.head(5).style\n",
    "\n",
    "# Modify the color and background color of the table headers (th)\n",
    "styled_df.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"color\", 'Black'), (\"background-color\", \"#FF00CC\"), ('font-weight', 'bold')]}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv = CountVectorizer()\n",
    "tfid = TfidfVectorizer(max_features = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'transformed_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'transformed_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m tfid\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformed_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m X_train, X_test , y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X,y,test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.20\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'transformed_text'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)\n",
    "# Save the fitted TfidfVectorizer to a file\n",
    "with open('tfid_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfid, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "}\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, clf \u001b[38;5;129;01min\u001b[39;00m clfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 5\u001b[0m     current_accuracy, current_precision, current_recall, current_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: name,\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: current_accuracy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m: current_f1\n\u001b[0;32m     12\u001b[0m     })\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[75], line 17\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_classifier\u001b[39m(clf, X_train, y_train, X_test, y_test):\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "results = []\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    current_accuracy, current_precision, current_recall, current_f1 = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    results.append({\n",
    "        'Classifier': name,\n",
    "        'Accuracy': current_accuracy,\n",
    "        'Precision': current_precision,\n",
    "        'Recall': current_recall,\n",
    "        'F1': current_f1\n",
    "    })\n",
    "    \n",
    "    # Save the trained model\n",
    "    with open(f'{name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('classification_metrics.csv', index=False)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
